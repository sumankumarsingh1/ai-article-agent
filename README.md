# ğŸ§  AI Article Agent  
A hands-on project to learn how to use Local and Cloud LLMs to generate high-quality written content.

---

## ğŸ“Œ Project Overview

The **AI Article Agent** is a beginner-friendly project designed for students learning how to work with Large Language Models (LLMs).  
This project demonstrates how AI can:

- Research a topic  
- Create a structured outline  
- Generate a complete article  
- Produce a short social media post summarizing the content  

It supports both:

- ğŸ–¥ Local LLMs (via **Ollama**)  
- ğŸŒ Cloud-based LLMs (via **OpenRouter.ai**)  

This makes it ideal for learning hybrid AI application development.

---

## ğŸš€ Features

âœ”ï¸ Works with multiple LLM providers  
âœ”ï¸ Fully automated article writing workflow  
âœ”ï¸ Search-assisted topic research using DuckDuckGo  
âœ”ï¸ Generates:

- ğŸ“ Full-length article  
- ğŸ“Œ Short summary post  
- ğŸ“ Outputs saved locally  

âœ”ï¸ Built for education and experimentation

---

## ğŸ› ï¸ Prerequisites

### 1ï¸âƒ£ Install Ollama

Download from:

ğŸ‘‰ https://ollama.com/download  

Pull at least one model, for example:

```bash
ollama pull llama3
```

### 2ï¸âƒ£ Create a .env file with your OpenRouter Key

Create a file named .env in the project folder and add:

```bash
OPENROUTER_API_KEY=your_api_key_here
```

ğŸ“ This is optional â€” only needed if you want to use remote cloud LLMs.


### 3ï¸âƒ£ (Optional) Update models.json

You can configure which models the app will use.

Example block to add:
```bash
    {
      "name": "mistral (OpenRouter)",
      "type": "openrouter",
      "params": {
        "model": "mistralai/mistral-7b-instruct:free",
        "base_url": "https://openrouter.ai/api/v1"
      }
    },   
```

### ğŸ“¦ Installation

Run the following commands:
```bash
git clone <repo-url>
cd ai-article-agent
pip install -r requirements.txt
```

### â–¶ï¸ Running the Application

Once installed, start the program:

```bash
python app.py
```



The system will guide you through:

1. Selecting a topic

2. Choosing a model (local or cloud)

3. Generating content

The agent will then:

* Research the topic

* Create an outline

* Generate a full article

* Create a short promotional post

* Save everything inside the output/ folder

ğŸ“ Project Structure
```bash
ai-article-agent/
â”‚
â”œâ”€â”€ app1.py                # Main executable workflow
â”œâ”€â”€ tools.py               # Functions for research + content generation
â”œâ”€â”€ llm_loader.py          # Handles model loading (local + cloud)
â”œâ”€â”€ models.json            # Model configuration file
â”œâ”€â”€ outputs/                # Folder storing generated content
â””â”€â”€ requirements.txt       # Project dependencies

```

ğŸ“ What You Will Learn

By completing this project, you will gain hands-on experience in:

* Using LLMs programmatically from Python

* Switching between local and cloud models

* Automating content generation workflows

* Integrating search-assisted research

* Building AI-powered productivity tools

* Saving structured output for reuse

### âœ¨ Optional Future Enhancements
| Feature | Difficulty	| Status |
| ------- | ----------- | ------ |
| Web UI with Gradio | â­â­ | Planned |
| SEO keyword extraction | â­â­â­ | Optional |
| Banner image generation via Stable Diffusion | â­â­â­â­ | Optional |
| Text-to-speech article narration	| â­â­ | Optional


### ğŸ¤ Contributing
* This is a learning-focused project â€” feel free to fork, improve, and create pull requests.
* Suggestions and enhancements are always welcome!
* Share with us what good learnings you had.

### ğŸ“„ License

Licensed under the MIT License â€” free to use, modify, and share.